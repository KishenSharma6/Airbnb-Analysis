{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "Data Cleaning - Aggregated Airbnb Listings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In the following notebook, I will be cleaning an aggregation of Airbnb listings data. This data pertains to the San Francisco area and consists of calendar data from 12/2018 through 12/2019.\n",
    "\n",
    "The aggregation source code can be found [here](https://github.com/KishenSharma6/Airbnb-Analysis/blob/master/Project%20Codes/01.%20Raw%20Data%20Aggregation%20Scripts/2020_0129_Airbnb_Raw_Data_Aggregation.ipynb)\n",
    "\n",
    "Raw data can be found [here](https://github.com/KishenSharma6/Airbnb-Analysis/tree/master/Data/01_Raw/SF%20Airbnb%20Raw%20Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in libraries,  read in data, and set notebook preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in libraries\n",
    "import pandas as pd\n",
    "import swifter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set notebook preferences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supress future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#Set options for pandas\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows',200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path to get aggregated listings data\n",
    "path = r'C:\\Users\\kishe\\Documents\\Data Science\\Projects\\Python Projects\\In Progress\\Air BnB - SF\\Data\\01_Raw\\SF Airbnb Raw Data\\SF Airbnb Raw Data - Aggregated\\01_04_2020_Listings_Raw_Aggregated.csv'\n",
    "\n",
    "#list columns with date information to parse\n",
    "dates = ['calendar_last_scraped', 'first_review', 'host_since', 'last_review']\n",
    "\n",
    "#Read in Airbnb listings Data\n",
    "listings = pd.read_csv(path,index_col=0, low_memory=False, \n",
    "                       dtype={'review_scores_accuracy':'object',\n",
    "                              'review_scores_checkin':'object',\n",
    "                              'review_scores_cleanliness':'object',\n",
    "                              'review_scores_communication':'object',\n",
    "                              'review_scores_location':'object',\n",
    "                             'review_scores_rating':'object',\n",
    "                             'review_scores_value':'object'} ,\n",
    "                               sep=',', parse_dates=dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Listings shape:', listings.shape)\n",
    "display(listings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.filter(regex='review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View data types\n",
    "listings.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Column removal for collinearity or homogeneous values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test for and remove collinear features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a correlation matrix\n",
    "corr_matrix = listings.corr().abs()\n",
    "\n",
    "#Select upper triangle of matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "#Find features with correlation greater than 0.9\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
    "\n",
    "print('Columns with a correlation > .9:\\n', to_drop)\n",
    "\n",
    "#Drop\n",
    "listings.drop(columns=to_drop,inplace=True)\n",
    "\n",
    "#View updated listings shape\n",
    "print('\\nUpdated listings shape: ',listings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove columns with homogenous values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture columns with homogeneous values and store as list in cols\n",
    "cols = list(listings.columns[listings.nunique() == 1])\n",
    "\n",
    "#Drop cols\n",
    "listings.drop(columns=cols, axis = 1, inplace=True)\n",
    "\n",
    "#View updated listings shape\n",
    "print('Updated listings shape: ',listings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for additional columns with mostly homogenous values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture columns with homogeneous values and store as list in cols\n",
    "cols = listings.columns[listings.nunique() <= 2]\n",
    "\n",
    "#Check\n",
    "display(listings[cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore values in country, country_code, jurisdiction_names, and market\n",
    "print(listings.groupby('country')['country'].count())\n",
    "print('\\n',listings.groupby('country_code')['country_code'].count())\n",
    "print('\\n',listings.groupby('jurisdiction_names')['jurisdiction_names'].count())\n",
    "print('\\n',listings.groupby('market')['market'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping cols, data pertains to sf. Errors may be due to location of host\n",
    "listings.drop(columns=['country','country_code','jurisdiction_names','market'], inplace = True)\n",
    "\n",
    "#Updated listings shape\n",
    "print('Updated listings shape:', listings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing redundant columns\n",
    "\n",
    "Columns city, street, and smart_location  encode the same information. Columns neighbourhood and neighbourhood_cleansed do the same. \n",
    "\n",
    "Keeping city and neighbourhood_cleansed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cols to drop\n",
    "cols = ['street', 'smart_location','neighbourhood']\n",
    "\n",
    "#Dropping redundant columns\n",
    "listings.drop(columns=cols, inplace=True)\n",
    "\n",
    "#Updated listings shape\n",
    "print('Updated listings shape:', listings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column removal for containing unusable/unnecessary data\n",
    "\n",
    "Columns containing url links or web scrape information are not needed for this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop cols ending in url\n",
    "listings = listings[listings.columns.drop(list(listings.filter(regex='url$')))]\n",
    "\n",
    "#Check\n",
    "listings.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop cols containing scrape\n",
    "listings = listings[listings.columns.drop(list(listings.filter(regex='scrape')))]\n",
    "\n",
    "#Check\n",
    "listings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting continuous variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of cols that contain $%,{}[]\"'\n",
    "cols = ['cleaning_fee','extra_people','host_response_rate','monthly_price', 'price', 'security_deposit',\n",
    "        'weekly_price']\n",
    "\n",
    "#Remove $%, and convert cols to floats\n",
    "listings[cols] = listings[cols].replace('[$,%]', '', regex=True).astype('float64')\n",
    "\n",
    "#Check\n",
    "print('Cols dtypes:\\n', listings[cols].dtypes)\n",
    "display(listings[cols].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting string variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols with troublesome punctuation\n",
    "cols = ['amenities', 'host_verifications']\n",
    "\n",
    "#Remove punctuation\n",
    "listings[cols] = listings[cols].replace('[^\\w\\s]+', ' ', regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting boolean variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of columns to convert t's to 1's and f's to 0's\n",
    "cols = ['host_has_profile_pic','host_identity_verified','host_is_superhost', 'instant_bookable',\n",
    "       'is_location_exact', 'require_guest_phone_verification',\t'require_guest_profile_picture', 'requires_license']\n",
    "\n",
    "#Strip white space in strings\n",
    "listings[cols] = listings[cols].apply(lambda x: x.str.strip())\n",
    "\n",
    "#Create dictionary to map True and False\n",
    "mymap = {'t':True, 'f':False}\n",
    "\n",
    "#Replace t's and f's\n",
    "listings[cols]=listings[cols].applymap(lambda s: mymap.get(s) if s in mymap else s)\n",
    "\n",
    "#Convert cols to bool\n",
    "listings[cols] = listings[cols].astype('bool')\n",
    "\n",
    "#Check\n",
    "print('Cols dtypes:\\n', listings[cols].dtypes)\n",
    "display(listings[cols].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a missing data tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_tracker(pandas):\n",
    "#function that returns a df containing the count and % of missing values per cool in pandas.\n",
    "#Also captures dtype per col in pandas for easier cleaning\n",
    "    missing = pd.DataFrame()\n",
    "    missing['total'] = pandas.isna().sum()\n",
    "    missing['missing%'] = missing['total']/len(pandas)\n",
    "    missing['dtype'] = pandas.dtypes\n",
    "    missing = missing[missing.total > 1].sort_values(by ='total',ascending = False)\n",
    "    return missing\n",
    "\n",
    "#View missing data in listings\n",
    "missing = missing_tracker(listings)\n",
    "display(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns missing more than 40% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get names of cols with more than 40% of values missing\n",
    "cols = missing[missing['missing%'] > .40].index.tolist()\n",
    "\n",
    "#Drop cols\n",
    "listings.drop(columns=cols, inplace=True)\n",
    "\n",
    "#Update and display missing values\n",
    "missing = missing_tracker(listings)\n",
    "display(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolve floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset flaots from listings\n",
    "floats = missing[missing['dtype'] == 'float64'].index.tolist()\n",
    "\n",
    "#View stats\n",
    "print('Median values : \\n', listings[floats].median())\n",
    "listings[floats].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling with median values due to pull from airbnb luxe listings\n",
    "listings[floats] = listings[floats].fillna(listings[floats].median())\n",
    "\n",
    "#Update and display missing values\n",
    "missing = missing_tracker(listings)\n",
    "display(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolve objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preview object columns from listings that contain missing values\n",
    "objects = missing.loc[missing.dtype == 'object'].index.to_list()\n",
    "listings[objects].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text entry variables/host information to fill with 'Unavailable'\n",
    "unavailable = ['notes','license','access','interaction','transit','house_rules','space',\n",
    "               'summary','description','host_about','host_location', 'host_name','host_neighbourhood','neighborhood_overview']\n",
    "#Fill \n",
    "listings[unavailable] = listings[unavailable].fillna('Unavailable')\n",
    "\n",
    "#Categorical variables to fill with the mode of the column\n",
    "mode = ['review_scores_value', 'review_scores_location', 'review_scores_checkin', 'review_scores_accuracy',\n",
    "        'review_scores_cleanliness', 'review_scores_communication', 'review_scores_rating','host_response_time', 'cancellation_policy','city','state']\n",
    "#Fill\n",
    "for col in mode:\n",
    "    listings[col].fillna(listings[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverse engineer missing zipcode. Import libraries to reverse engineer zipcode\n",
    "from uszipcode import SearchEngine\n",
    "from uszipcode import Zipcode\n",
    "\n",
    "#Instantiate SearchEngine\n",
    "zipsearch = SearchEngine(simple_zipcode=True)\n",
    "\n",
    "#Write function that finds zip given lat and long data\n",
    "def get_zipcode(lat, lon):\n",
    "    result = zipsearch.by_coordinates(lat = lat, lng = lon, returns = 1)\n",
    "    return result[0].zipcode\n",
    "\n",
    "temp = listings[listings.zipcode.isna()][['latitude', 'longitude']]\n",
    "\n",
    "#Apply get_zipcode and assign to Zipcode\n",
    "temp['zipcode']= temp.swifter.apply(lambda x: get_zipcode(x.latitude, x.longitude), axis =1)\n",
    "\n",
    "#Combine temp.Zipcode onto original df. \n",
    "listings.zipcode = listings.zipcode.combine_first(temp.zipcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing dates will be left as is for the time being"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated listings shape\n",
    "print('Updated listings shape:', listings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Column Specific Cleaning\n",
    "\n",
    "Cleaning specific columns in listings data in which there were specific value issues spotted in the Pandas Profiling report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View values in city column\n",
    "listings.groupby('city')['city'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strip white space\n",
    "listings.city = listings.city.str.strip()\n",
    "\n",
    "#Replace neighborhood information with San Fancisco and correct Daly City Spelling\n",
    "listings.city.replace('^(B|San|No|V|[^a-zA-Z]).*', 'San Francisco', regex=True, inplace=True)\n",
    "listings.city.replace('^D.*', 'Daly City', regex=True, inplace=True)\n",
    "\n",
    "\n",
    "#Check\n",
    "listings.groupby('city')['city'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calendar_updated column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert 'a week ago' to '1 week ago' in calendar_updated\n",
    "listings['calendar_updated'].replace('a week ago', '1 week ago', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View stats over price\n",
    "print('Median Price : ', listings.price.median())\n",
    "listings.price.describe(percentiles=[.1,.2,.3,.4,.5,.6,.7,.8,.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows where price = 0 (Typo)\n",
    "listings = listings[listings['price'] >0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming some column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting calculated_host_listings to chl\n",
    "listings.rename(columns={'calculated_host_listings_count': 'chlc',\n",
    "'calculated_host_listings_count_private_rooms':'chlc_private_rooms',\n",
    "'calculated_host_listings_count_shared_rooms':'chlc_shared_rooms'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final shape of listings is:',listings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path to write listings\n",
    "path = r'C:\\Users\\kishe\\Documents\\Data Science\\Projects\\Python Projects\\In Progress\\Air BnB - SF\\Data\\02_Intermediate\\2020_0201_Listings_Cleaned.csv'\n",
    "\n",
    "#Write listings to path\n",
    "listings.to_csv(path, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
